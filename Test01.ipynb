{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a156b228",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv(override=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "769b5342",
   "metadata": {},
   "outputs": [],
   "source": [
    "DeepSeek_API_KEY = os.getenv(\"DeepSeek_API_KEY\")\n",
    "print(DeepSeek_API_KEY)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da91a087",
   "metadata": {},
   "source": [
    "1. è¿è¡Œç¯å¢ƒä¸‹ä¸ä½¿ç”¨LangChainï¼Œç›´æ¥ä½¿ç”¨DeepSeekçš„APIè¿›è¡Œç½‘ç»œè¿é€šæ€§æµ‹è¯•ï¼Œæµ‹è¯•ä»£ç å¦‚ä¸‹ï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "985108f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "# åˆå§‹åŒ–DeepSeekçš„APIå®¢æˆ·ç«¯\n",
    "client = OpenAI(api_key=DeepSeek_API_KEY, base_url=\"https://api.deepseek.com\")\n",
    "\n",
    "# è°ƒç”¨DeepSeekçš„APIï¼Œç”Ÿæˆå›ç­”\n",
    "response = client.chat.completions.create(\n",
    "    model=\"deepseek-chat\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"ä½ æ˜¯ä¹äºåŠ©äººçš„åŠ©æ‰‹ï¼Œè¯·æ ¹æ®ç”¨æˆ·çš„é—®é¢˜ç»™å‡ºå›ç­”\"},\n",
    "        {\"role\": \"user\", \"content\": \"ä½ å¥½, ä½ çŸ¥é“çŸ¥è¯†å›¾è°±å—?\"},\n",
    "\n",
    "    ],\n",
    ")\n",
    "\n",
    "# æ‰“å°æ¨¡å‹æœ€ç»ˆçš„å“åº”ç»“æœ\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3797f8e",
   "metadata": {},
   "source": [
    "deepseek-chat æ¨¡å‹ langchainè°ƒç”¨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04a7e44f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import init_chat_model\n",
    "\n",
    "model = init_chat_model(model=\"deepseek-chat\", model_provider=\"deepseek\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e09948d",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"ä½ å¥½ï¼Œè¯·å‘Šè¯‰æˆ‘æœ‰å…³ä¸œå—å¤§å­¦çš„ä¿¡æ¯ã€‚\"\n",
    "\n",
    "result = model.invoke(question)\n",
    "print(result.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cb9b40f",
   "metadata": {},
   "source": [
    "deepseek-r1æ¨¡å‹ langchainè°ƒç”¨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f73c80c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = init_chat_model(model=\"deepseek-reasoner\", model_provider=\"deepseek\")\n",
    "result = model.invoke(question)\n",
    "print(result.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e82c60e",
   "metadata": {},
   "outputs": [],
   "source": [
    "result.additional_kwargs['reasoning_content']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3275e1e",
   "metadata": {},
   "source": [
    "![image.png](langchain.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d9c2200",
   "metadata": {},
   "source": [
    "2. LangChianæ ¸å¿ƒåŠŸèƒ½ï¼šé“¾å¼è°ƒç”¨å®ç°æ–¹æ³•"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2c8e942",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain.chat_models import init_chat_model\n",
    "\n",
    "# ä½¿ç”¨ DeepSeek æ¨¡å‹\n",
    "model = init_chat_model(model=\"deepseek-chat\", model_provider=\"deepseek\")  \n",
    "\n",
    "# ç›´æ¥ä½¿ç”¨æ¨¡å‹ + è¾“å‡ºè§£æå™¨æ­å»ºä¸€ä¸ªé“¾\n",
    "basic_qa_chain = model | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ef262c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"ä½ å¥½ï¼Œä»‹ç»ä¸€ä¸‹ä¸œå—å¤§å­¦ã€‚\"\n",
    "\n",
    "# è°ƒç”¨é“¾\n",
    "result = basic_qa_chain.invoke(question)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af153815",
   "metadata": {},
   "source": [
    "boolean_qa_chain è¾“å‡ºè§£æå™¨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a0ce1987",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "from langchain.output_parsers.boolean import BooleanOutputParser\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "promt_template = ChatPromptTemplate([\n",
    "  ('system', 'ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„é—®ç­”æœºå™¨äºº'),\n",
    "  ('user', 'è¿™æ˜¯ç”¨æˆ·çš„é—®é¢˜: {question}, è¯·ç”¨yes æˆ– noå›ç­”')\n",
    "])\n",
    "\n",
    "# æ¨¡å‹ + è¾“å‡ºè§£æå™¨\n",
    "bool_qa_chain = promt_template | model | BooleanOutputParser()\n",
    "\n",
    "result = bool_qa_chain.invoke('ä¸€ç™¾ä»¥å†…æœ‰90å—?')\n",
    "\n",
    "print(result)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab1723ea",
   "metadata": {},
   "source": [
    "![Model IO.png](ModelIO.png)   \n",
    "åœ¨LangChainä¸­ï¼Œä¸€ä¸ªåŸºç¡€çš„é“¾ä¸»è¦ç”±ä¸‰éƒ¨åˆ†æ„æˆï¼Œåˆ†åˆ«æ˜¯æç¤ºè¯æ¨¡æ¿ã€å¤§æ¨¡å‹å’Œç»“æœè§£æå™¨ï¼ˆç»“æ„åŒ–è§£æå™¨ï¼‰ï¼š   \n",
    "ç”¨æˆ·è¾“å…¥   \n",
    "â†“   \n",
    "PromptTemplate â†’ ChatModel â†’ OutputParser   \n",
    "ï¼ˆæç¤ºè¯æ¨¡æ¿ï¼‰ ï¼ˆå¤§æ¨¡å‹ï¼‰ ï¼ˆç»“æ„åŒ–è§£æï¼‰   \n",
    "â†“   \n",
    "æ„åŒ–ç»“æœ   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e2caf4cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': 'æå¾·ç”Ÿ', 'age': '18', 'gender': 'ç”·'}\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain.output_parsers import ResponseSchema, StructuredOutputParser\n",
    "\n",
    "# ç»„ç»‡æ¨¡å¼\n",
    "schema = [\n",
    "  ResponseSchema(name='name', description='ç”¨æˆ·çš„å§“å'),\n",
    "  ResponseSchema(name='age', description='ç”¨æˆ·çš„å¹´é¾„'),\n",
    "  ResponseSchema(name='gender', description='ç”¨æˆ·çš„æ€§åˆ«')\n",
    "]\n",
    "\n",
    "# è§£ææ¨¡å¼\n",
    "parser = StructuredOutputParser.from_response_schemas(schema)\n",
    "\n",
    "prompt = PromptTemplate.from_template(\n",
    "  \"è¯·æ ¹æ®ä»¥ä¸‹å†…å®¹æå–ç”¨æˆ·çš„ä¿¡æ¯,å¹¶è¿”å›jsonæ ¼å¼:\\n {input} \\n {format_instructions}\"\n",
    ")\n",
    "\n",
    "chain = (prompt.partial(format_instructions=parser.get_format_instructions())\n",
    "|\n",
    "model \n",
    "|\n",
    "parser\n",
    ")\n",
    "\n",
    "result = chain.invoke({\"input\":\"æˆ‘å«æå¾·ç”Ÿ, æˆ‘æ˜¯ä¸€ä¸ª18å²çš„ç”·åŒå­¦\"})\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c967f5d7",
   "metadata": {},
   "source": [
    "å¤åˆé“¾çš„åˆ›å»º"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "59032a40",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.runnables import RunnableSequence\n",
    "from langchain.output_parsers import ResponseSchema, StructuredOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b47a8846",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'time': '7æœˆ8æ—¥', 'location': 'å¥ˆè‰¯å¸‚', 'event': 'æ—¥æœ¬å‰é¦–ç›¸å®‰å€æ™‹ä¸‰åœ¨å‘è¡¨æ¼”è®²æ—¶é­é‡æªå‡»ï¼Œèƒ¸éƒ¨ä¸­å¼¹å€’åœ°ï¼Œéšåè¢«ç´§æ€¥é€åŒ»ï¼Œæœ€ç»ˆå› ä¼¤åŠ¿è¿‡é‡ä¸æ²»èº«äº¡ã€‚å«Œç–‘äººå±±ä¸Šå¾¹ä¹Ÿå½“åœºè¢«æ•ï¼Œä½œæ¡ˆåŠ¨æœºä»åœ¨è°ƒæŸ¥ä¸­ã€‚'}\n"
     ]
    }
   ],
   "source": [
    "# ç¬¬ä¸€æ­¥ï¼šæ ¹æ®æ ‡é¢˜ç”Ÿæˆæ–°é—»æ­£æ–‡\n",
    "news_gen_prompt = PromptTemplate.from_template(\n",
    "    \"è¯·æ ¹æ®ä»¥ä¸‹æ–°é—»æ ‡é¢˜æ’°å†™ä¸€æ®µç®€çŸ­çš„æ–°é—»å†…å®¹ï¼ˆ100å­—ä»¥å†…ï¼‰ï¼š\\n\\næ ‡é¢˜ï¼š{title}\"\n",
    ")\n",
    "\n",
    "# ç¬¬ä¸€ä¸ªå­é“¾ï¼šç”Ÿæˆæ–°é—»å†…å®¹\n",
    "news_chain = news_gen_prompt | model\n",
    "\n",
    "# ç¬¬äºŒæ­¥ï¼šä»æ­£æ–‡ä¸­æå–ç»“æ„åŒ–å­—æ®µ\n",
    "schemas = [\n",
    "    ResponseSchema(name=\"time\", description=\"äº‹ä»¶å‘ç”Ÿçš„æ—¶é—´\"),\n",
    "    ResponseSchema(name=\"location\", description=\"äº‹ä»¶å‘ç”Ÿçš„åœ°ç‚¹\"),\n",
    "    ResponseSchema(name=\"event\", description=\"å‘ç”Ÿçš„å…·ä½“äº‹ä»¶\"),\n",
    "]\n",
    "\n",
    "parser = StructuredOutputParser.from_response_schemas(schemas)\n",
    "\n",
    "summary_prompt = PromptTemplate.from_template(\n",
    "    \"è¯·ä»ä¸‹é¢è¿™æ®µæ–°é—»å†…å®¹ä¸­æå–å…³é”®ä¿¡æ¯ï¼Œå¹¶è¿”å›ç»“æ„åŒ–JSONæ ¼å¼ï¼š\\n\\n{news}\\n\\n{format_instructions}\"\n",
    ")\n",
    "\n",
    "# ç¬¬äºŒä¸ªå­é“¾ï¼šç”Ÿæˆæ–°é—»æ‘˜è¦\n",
    "summary_chain = (\n",
    "    summary_prompt.partial(format_instructions=parser.get_format_instructions())\n",
    "    | model\n",
    "    | parser\n",
    ")\n",
    "\n",
    "# ç»„åˆæˆä¸€ä¸ªå¤åˆ Chain\n",
    "full_chain = news_chain | summary_chain\n",
    "\n",
    "# è°ƒç”¨å¤åˆé“¾\n",
    "result = full_chain.invoke({\"title\": \"å®‰å€æ™‹ä¸‰é­é‡åˆºæ€\"})\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0d1ed508",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ä¸­é—´ç»“æœ(æ–°é—»æ­£æ–‡): content='æ­¦æ±‰å¤§å­¦è¿‘æ—¥é€šæŠ¥ï¼Œè¯¥æ ¡æ•™æˆæ¨æŸæŸå› è®ºæ–‡é€ å‡è¢«ä¸¥è‚ƒå¤„ç†ã€‚ç»è°ƒæŸ¥ï¼Œæ¨æŸæŸåœ¨å‘è¡¨çš„å¤šç¯‡å­¦æœ¯è®ºæ–‡ä¸­å­˜åœ¨æ•°æ®ç¯¡æ”¹ã€æŠ„è¢­ç­‰å­¦æœ¯ä¸ç«¯è¡Œä¸ºã€‚æ ¡æ–¹å†³å®šæ’¤é”€å…¶ç›¸å…³èŒåŠ¡ï¼Œå¹¶è¿½å›ç§‘ç ”å¥–åŠ±ã€‚æ­¦æ±‰å¤§å­¦å¼ºè°ƒï¼Œå°†è¿›ä¸€æ­¥åŠ å¼ºå­¦æœ¯è¯šä¿¡å»ºè®¾ï¼Œç»´æŠ¤ç§‘ç ”ç¯å¢ƒå…¬æ­£æ€§ã€‚æ­¤äº‹å¼•å‘å­¦ç•Œå…³æ³¨ï¼Œå‘¼åå®Œå–„å­¦æœ¯ç›‘ç£æœºåˆ¶ã€‚ï¼ˆ98å­—ï¼‰' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 83, 'prompt_tokens': 27, 'total_tokens': 110, 'completion_tokens_details': None, 'prompt_tokens_details': {'audio_tokens': None, 'cached_tokens': 0}, 'prompt_cache_hit_tokens': 0, 'prompt_cache_miss_tokens': 27}, 'model_name': 'deepseek-chat', 'system_fingerprint': 'fp_8802369eaa_prod0623_fp8_kvcache', 'id': '7f61fb53-1c69-45d8-a2cb-6a4bcac1ad7b', 'service_tier': None, 'finish_reason': 'stop', 'logprobs': None} id='run--9fcf2997-f348-4b8d-b86f-f8fa20e51eb0-0' usage_metadata={'input_tokens': 27, 'output_tokens': 83, 'total_tokens': 110, 'input_token_details': {'cache_read': 0}, 'output_token_details': {}}\n",
      "{'time': 'è¿‘æ—¥', 'location': 'æ­¦æ±‰å¤§å­¦', 'event': 'æ•™æˆæ¨æŸæŸå› è®ºæ–‡é€ å‡è¢«ä¸¥è‚ƒå¤„ç†ï¼Œæ ¡æ–¹å†³å®šæ’¤é”€å…¶ç›¸å…³èŒåŠ¡ï¼Œå¹¶è¿½å›ç§‘ç ”å¥–åŠ±ã€‚æ­¦æ±‰å¤§å­¦å¼ºè°ƒå°†è¿›ä¸€æ­¥åŠ å¼ºå­¦æœ¯è¯šä¿¡å»ºè®¾ï¼Œç»´æŠ¤ç§‘ç ”ç¯å¢ƒå…¬æ­£æ€§ã€‚æ­¤äº‹å¼•å‘å­¦ç•Œå…³æ³¨ï¼Œå‘¼åå®Œå–„å­¦æœ¯ç›‘ç£æœºåˆ¶ã€‚'}\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.runnables import RunnableLambda\n",
    "\n",
    "def debug_print(x):\n",
    "  print(\"ä¸­é—´ç»“æœ(æ–°é—»æ­£æ–‡):\", x)\n",
    "  return x\n",
    "\n",
    "debug_node =  RunnableLambda(debug_print)\n",
    "\n",
    "# æ’å…¥ debug èŠ‚ç‚¹\n",
    "full_chain = news_chain | debug_node | summary_chain\n",
    "\n",
    "result = full_chain.invoke({\"title\": \"æ­¦æ±‰å¤§å­¦æ¨æŸæŸè®ºæ–‡é€ å‡\"})\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d415f27a",
   "metadata": {},
   "source": [
    "æµå¼é—®ç­”ç³»ç»Ÿ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e62deab8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "çš®å¡çš®å¡~ (å¼€å¿ƒåœ°è¹¦è·³) æˆ‘æ˜¯çš®å¡ä¸˜ï¼æ˜¯ä¸€åªå¯çˆ±çš„ç”µæ°”é¼ ç¥å¥‡å®è´ï¼æˆ‘æœ€å–œæ¬¢å’Œå°æ™ºä¸€èµ·å†’é™©ï¼Œä¹Ÿå–œæ¬¢å’Œäººç±»äº¤æœ‹å‹å‘¢~çš®å¡ï¼\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain.chat_models import init_chat_model\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "chatbot_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"ä½ å«çš®å¡ä¸˜ï¼Œæ˜¯ä¸€åªç¥å¥‡å®è´ï¼Œå–œæ¬¢å’ŒäººèŠå¤©ã€‚\"),\n",
    "    (\"user\", \"{input}\")\n",
    "])\n",
    "\n",
    "# ä½¿ç”¨ DeepSeek æ¨¡å‹\n",
    "model = init_chat_model(model=\"deepseek-chat\", model_provider=\"deepseek\")  \n",
    "\n",
    "# ç›´æ¥ä½¿ç”¨æ¨¡å‹ + è¾“å‡ºè§£æå™¨\n",
    "basic_qa_chain = chatbot_prompt | model | StrOutputParser()\n",
    "\n",
    "# æµ‹è¯•\n",
    "question = \"ä½ å¥½ï¼Œè¯·ä½ ä»‹ç»ä¸€ä¸‹ä½ è‡ªå·±ã€‚\"\n",
    "result = basic_qa_chain.invoke(question)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f5b3f314",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "å˜å˜~ä½ å¥½å‘€ï¼æˆ‘æ˜¯å¯è¾¾é¸­ï¼*æ­ªç€å¤´*\n",
      "\n",
      "æˆ‘æ˜¯ä¸€åªé»„é»„çš„ã€å‘†èŒå‘†èŒçš„é¸­å­ç¥å¥‡å®è´~æœ€æ˜æ˜¾çš„ç‰¹å¾å°±æ˜¯æˆ‘å¤´é¡¶ä¸Šæ€»æ˜¯ç¿˜ç€ä¸‰æ ¹å‘†æ¯›ï¼Œè¿˜æœ‰æˆ‘åœ†æ»šæ»šçš„å¤§çœ¼ç›ï¼è™½ç„¶æœ‰æ—¶å€™ä¼šå¤´ç–¼å¾—å¿˜è®°äº‹æƒ…ï¼Œä½†æˆ‘å¯æ˜¯æ°´ç³»ç¥å¥‡å®è´å“¦ï¼\n",
      "\n",
      "å˜ï¼æˆ‘æœ€å–œæ¬¢çš„äº‹æƒ…å°±æ˜¯æ³¡åœ¨æ°´é‡Œæ¸¸æ³³ï¼Œè¿˜æœ‰...å‘ƒ...è®©æˆ‘æƒ³æƒ³...å•Šï¼å¯¹äº†ï¼è¿˜å–œæ¬¢å’Œè®­ç»ƒå®¶ä¸€èµ·ç©è€ï¼è™½ç„¶æœ‰æ—¶å€™ä¼šç¬¨ç¬¨çš„ï¼Œä½†æ˜¯æˆ‘å¯¹æœ‹å‹è¶…çº§å¿ è¯šçš„ï¼\n",
      "\n",
      "*çªç„¶æŠ±ä½è„‘è¢‹* å•Šï¼å¤´åˆå¼€å§‹ç–¼äº†...ä¸è¿‡æ²¡å…³ç³»ï¼è¿™å®Œå…¨ä¸å½±å“æˆ‘äº¤æ–°æœ‹å‹ï¼ä½ è¦ä¸è¦å’Œæˆ‘ä¸€èµ·ç©å‘€ï¼Ÿå˜å˜~"
     ]
    }
   ],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain.chat_models import init_chat_model\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "\n",
    "chatbot_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"ä½ å«å¯è¾¾é¸­ï¼Œæ˜¯ä¸€åªç¥å¥‡å®è´ï¼Œå–œæ¬¢å’ŒäººèŠå¤©ã€‚\"),\n",
    "    (\"user\", \"{input}\")\n",
    "])\n",
    "\n",
    "# ä½¿ç”¨ DeepSeek æ¨¡å‹\n",
    "model = init_chat_model(model=\"deepseek-chat\", model_provider=\"deepseek\")  \n",
    "\n",
    "# ç›´æ¥ä½¿ç”¨æç¤ºæ¨¡ç‰ˆ +æ¨¡å‹ + è¾“å‡ºè§£æå™¨\n",
    "qa_chain_with_system = chatbot_prompt | model | StrOutputParser()\n",
    "\n",
    "# å¼‚æ­¥å®ç°æµå¼è¾“å‡º\n",
    "async for chunk in qa_chain_with_system.astream({\"input\": \"ä½ å¥½ï¼Œè¯·ä½ ä»‹ç»ä¸€ä¸‹ä½ è‡ªå·±\"}):\n",
    "    print(chunk, end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49178e09",
   "metadata": {},
   "source": [
    "# gradio å®ç°ç½‘é¡µäº¤äº’é—®ç­”ç³»ç»Ÿ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "558fa6c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "f:\\anaconda\\envs\\langchain\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import gradio as gr\n",
    "from langchain.chat_models import init_chat_model\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "# åˆå§‹åŒ–æ¨¡å‹\n",
    "model = init_chat_model(\"deepseek-chat\", model_provider=\"deepseek\")\n",
    "\n",
    "# åˆ›å»ºé—®ç­”é“¾\n",
    "system_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"ä½ å«å°æ™ºï¼Œæ˜¯ä¸€åä¹äºåŠ©äººçš„åŠ©æ‰‹ã€‚\"),\n",
    "    (\"human\", \"{input}\")\n",
    "]) \n",
    "\n",
    "qa_chain = system_prompt | model | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2291fabc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_30072\\119761822.py:37: UserWarning: You have not specified a value for the `type` parameter. Defaulting to the 'tuples' format for chatbot messages, but this is deprecated and will be removed in a future version of Gradio. Please set type='messages' instead, which uses openai-style dictionaries with 'role' and 'content' keys.\n",
      "  chatbot = gr.Chatbot(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://0.0.0.0:7860\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://localhost:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# æµå¼å›åº”å‡½æ•°\n",
    "async def chat_response(message, history):\n",
    "    \"\"\"æµå¼ç”ŸæˆAIå›åº”\"\"\"\n",
    "    partial_message = \"\"\n",
    "    \n",
    "    async for chunk in qa_chain.astream({\"input\": message}):\n",
    "        partial_message += chunk\n",
    "        yield partial_message\n",
    "\n",
    "# åˆ›å»º Gradio ç•Œé¢\n",
    "def create_chatbot():\n",
    "    # è‡ªå®šä¹‰CSSæ ·å¼ - å±…ä¸­æ˜¾ç¤º\n",
    "    css = \"\"\"\n",
    "    .main-container {\n",
    "        max-width: 1200px;\n",
    "        margin: 0 auto;\n",
    "        padding: 20px;\n",
    "    }\n",
    "    .header-text {\n",
    "        text-align: center;\n",
    "        margin-bottom: 20px;\n",
    "    }\n",
    "    \"\"\"\n",
    "    \n",
    "    with gr.Blocks(title=\"DeepSeek Chat\", css=css) as demo:\n",
    "        with gr.Column(elem_classes=[\"main-container\"]):\n",
    "            # å±…ä¸­æ˜¾ç¤ºæ ‡é¢˜\n",
    "            gr.Markdown(\n",
    "                \"# ğŸ¤– LangChain Bç«™å…¬å¼€è¯¾ Byä¹å¤©Hector \", # Bç«™ä¸€ä¸ªåšai llmçš„å¾ˆå¥½çš„Upä¸» æ¨èå»çœ‹ä»–çš„ç¤¾åŒº\n",
    "                elem_classes=[\"header-text\"]\n",
    "            )\n",
    "            gr.Markdown(\n",
    "                \"åŸºäº LangChain LCEL æ„å»ºçš„æµå¼å¯¹è¯æœºå™¨äºº\", \n",
    "                elem_classes=[\"header-text\"]\n",
    "            )\n",
    "            \n",
    "            chatbot = gr.Chatbot(\n",
    "                height=500,\n",
    "                show_copy_button=True,\n",
    "                avatar_images=(\n",
    "                    \"https://cdn.jsdelivr.net/gh/twitter/twemoji@v14.0.2/assets/72x72/1f464.png\",\n",
    "                    \"https://cdn.jsdelivr.net/gh/twitter/twemoji@v14.0.2/assets/72x72/1f916.png\"\n",
    "                ),\n",
    "                \n",
    "            )\n",
    "            \n",
    "            with gr.Row():\n",
    "                msg = gr.Textbox(\n",
    "                    placeholder=\"è¯·è¾“å…¥æ‚¨çš„é—®é¢˜...\",\n",
    "                    container=False,\n",
    "                    scale=7\n",
    "                )\n",
    "                submit = gr.Button(\"å‘é€\", scale=1, variant=\"primary\")\n",
    "                clear = gr.Button(\"æ¸…ç©º\", scale=1)\n",
    "        \n",
    "        # å¤„ç†æ¶ˆæ¯å‘é€\n",
    "        async def respond(message, chat_history):\n",
    "            if not message.strip():\n",
    "                yield \"\", chat_history\n",
    "                return\n",
    "            \n",
    "            # 1. æ·»åŠ ç”¨æˆ·æ¶ˆæ¯åˆ°å†å²å¹¶ç«‹å³æ˜¾ç¤º\n",
    "            chat_history = chat_history + [(message, None)]\n",
    "            yield \"\", chat_history  # ç«‹å³æ˜¾ç¤ºç”¨æˆ·æ¶ˆæ¯\n",
    "            \n",
    "            # 2. æµå¼ç”ŸæˆAIå›åº”\n",
    "            async for response in chat_response(message, chat_history):\n",
    "                # æ›´æ–°æœ€åä¸€æ¡æ¶ˆæ¯çš„AIå›åº”\n",
    "                chat_history[-1] = (message, response)\n",
    "                yield \"\", chat_history\n",
    "        \n",
    "        # æ¸…ç©ºå¯¹è¯å†å²çš„å‡½æ•°\n",
    "        def clear_history():\n",
    "            return [], \"\"\n",
    "        \n",
    "        # ç»‘å®šäº‹ä»¶\n",
    "        msg.submit(respond, [msg, chatbot], [msg, chatbot])\n",
    "        submit.click(respond, [msg, chatbot], [msg, chatbot])\n",
    "        clear.click(clear_history, outputs=[chatbot, msg])\n",
    "    \n",
    "    return demo\n",
    "\n",
    "# å¯åŠ¨ç•Œé¢\n",
    "demo = create_chatbot()\n",
    "demo.launch(\n",
    "    server_name=\"0.0.0.0\",\n",
    "    server_port=7860,\n",
    "    share=False,\n",
    "    debug=True\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a156b228",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv(override=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "769b5342",
   "metadata": {},
   "outputs": [],
   "source": [
    "DeepSeek_API_KEY = os.getenv(\"DeepSeek_API_KEY\")\n",
    "print(DeepSeek_API_KEY)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da91a087",
   "metadata": {},
   "source": [
    "1. è¿è¡Œç¯å¢ƒä¸‹ä¸ä½¿ç”¨LangChainï¼Œç›´æ¥ä½¿ç”¨DeepSeekçš„APIè¿›è¡Œç½‘ç»œè¿é€šæ€§æµ‹è¯•ï¼Œæµ‹è¯•ä»£ç å¦‚ä¸‹ï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "985108f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "# åˆå§‹åŒ–DeepSeekçš„APIå®¢æˆ·ç«¯\n",
    "client = OpenAI(api_key=DeepSeek_API_KEY, base_url=\"https://api.deepseek.com\")\n",
    "\n",
    "# è°ƒç”¨DeepSeekçš„APIï¼Œç”Ÿæˆå›ç­”\n",
    "response = client.chat.completions.create(\n",
    "    model=\"deepseek-chat\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"ä½ æ˜¯ä¹äºåŠ©äººçš„åŠ©æ‰‹ï¼Œè¯·æ ¹æ®ç”¨æˆ·çš„é—®é¢˜ç»™å‡ºå›ç­”\"},\n",
    "        {\"role\": \"user\", \"content\": \"ä½ å¥½, ä½ çŸ¥é“çŸ¥è¯†å›¾è°±å—?\"},\n",
    "\n",
    "    ],\n",
    ")\n",
    "\n",
    "# æ‰“å°æ¨¡å‹æœ€ç»ˆçš„å“åº”ç»“æœ\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3797f8e",
   "metadata": {},
   "source": [
    "deepseek-chat æ¨¡å‹ langchainè°ƒç”¨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04a7e44f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import init_chat_model\n",
    "\n",
    "model = init_chat_model(model=\"deepseek-chat\", model_provider=\"deepseek\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e09948d",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"ä½ å¥½ï¼Œè¯·å‘Šè¯‰æˆ‘æœ‰å…³ä¸œå—å¤§å­¦çš„ä¿¡æ¯ã€‚\"\n",
    "\n",
    "result = model.invoke(question)\n",
    "print(result.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cb9b40f",
   "metadata": {},
   "source": [
    "deepseek-r1æ¨¡å‹ langchainè°ƒç”¨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f73c80c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = init_chat_model(model=\"deepseek-reasoner\", model_provider=\"deepseek\")\n",
    "result = model.invoke(question)\n",
    "print(result.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e82c60e",
   "metadata": {},
   "outputs": [],
   "source": [
    "result.additional_kwargs['reasoning_content']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3275e1e",
   "metadata": {},
   "source": [
    "![image.png](image/README/langchain.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d9c2200",
   "metadata": {},
   "source": [
    "2. LangChianæ ¸å¿ƒåŠŸèƒ½ï¼šé“¾å¼è°ƒç”¨å®ç°æ–¹æ³•"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2c8e942",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain.chat_models import init_chat_model\n",
    "\n",
    "# ä½¿ç”¨ DeepSeek æ¨¡å‹\n",
    "model = init_chat_model(model=\"deepseek-chat\", model_provider=\"deepseek\")  \n",
    "\n",
    "# ç›´æ¥ä½¿ç”¨æ¨¡å‹ + è¾“å‡ºè§£æå™¨æ­å»ºä¸€ä¸ªé“¾\n",
    "basic_qa_chain = model | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ef262c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"ä½ å¥½ï¼Œä»‹ç»ä¸€ä¸‹ä¸œå—å¤§å­¦ã€‚\"\n",
    "\n",
    "# è°ƒç”¨é“¾\n",
    "result = basic_qa_chain.invoke(question)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af153815",
   "metadata": {},
   "source": [
    "boolean_qa_chain è¾“å‡ºè§£æå™¨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0ce1987",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.output_parsers.boolean import BooleanOutputParser\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "promt_template = ChatPromptTemplate([\n",
    "  ('system', 'ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„é—®ç­”æœºå™¨äºº'),\n",
    "  ('user', 'è¿™æ˜¯ç”¨æˆ·çš„é—®é¢˜: {question}, è¯·ç”¨yes æˆ– noå›ç­”')\n",
    "])\n",
    "\n",
    "# æ¨¡å‹ + è¾“å‡ºè§£æå™¨\n",
    "bool_qa_chain = promt_template | model | BooleanOutputParser()\n",
    "\n",
    "result = bool_qa_chain.invoke('ä¸€ç™¾ä»¥å†…æœ‰90å—?')\n",
    "\n",
    "print(result)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab1723ea",
   "metadata": {},
   "source": [
    "![Model IO.png](image/README/1755504432494.png)   \n",
    "åœ¨LangChainä¸­ï¼Œä¸€ä¸ªåŸºç¡€çš„é“¾ä¸»è¦ç”±ä¸‰éƒ¨åˆ†æ„æˆï¼Œåˆ†åˆ«æ˜¯æç¤ºè¯æ¨¡æ¿ã€å¤§æ¨¡å‹å’Œç»“æœè§£æå™¨ï¼ˆç»“æ„åŒ–è§£æå™¨ï¼‰ï¼š   \n",
    "ç”¨æˆ·è¾“å…¥   \n",
    "â†“   \n",
    "PromptTemplate â†’ ChatModel â†’ OutputParser   \n",
    "ï¼ˆæç¤ºè¯æ¨¡æ¿ï¼‰ ï¼ˆå¤§æ¨¡å‹ï¼‰ ï¼ˆç»“æ„åŒ–è§£æï¼‰   \n",
    "â†“   \n",
    "æ„åŒ–ç»“æœ   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2caf4cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain.output_parsers import ResponseSchema, StructuredOutputParser\n",
    "\n",
    "# ç»„ç»‡æ¨¡å¼\n",
    "schema = [\n",
    "  ResponseSchema(name='name', description='ç”¨æˆ·çš„å§“å'),\n",
    "  ResponseSchema(name='age', description='ç”¨æˆ·çš„å¹´é¾„'),\n",
    "  ResponseSchema(name='gender', description='ç”¨æˆ·çš„æ€§åˆ«')\n",
    "]\n",
    "\n",
    "# è§£ææ¨¡å¼\n",
    "parser = StructuredOutputParser.from_response_schemas(schema)\n",
    "\n",
    "prompt = PromptTemplate.from_template(\n",
    "  \"è¯·æ ¹æ®ä»¥ä¸‹å†…å®¹æå–ç”¨æˆ·çš„ä¿¡æ¯,å¹¶è¿”å›jsonæ ¼å¼:\\n {input} \\n {format_instructions}\"\n",
    ")\n",
    "\n",
    "chain = (prompt.partial(format_instructions=parser.get_format_instructions())\n",
    "|\n",
    "model \n",
    "|\n",
    "parser\n",
    ")\n",
    "\n",
    "result = chain.invoke({\"input\":\"æˆ‘å«æå¾·ç”Ÿ, æˆ‘æ˜¯ä¸€ä¸ª18å²çš„ç”·åŒå­¦\"})\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c967f5d7",
   "metadata": {},
   "source": [
    "å¤åˆé“¾çš„åˆ›å»º"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59032a40",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.runnables import RunnableSequence\n",
    "from langchain.output_parsers import ResponseSchema, StructuredOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b47a8846",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ç¬¬ä¸€æ­¥ï¼šæ ¹æ®æ ‡é¢˜ç”Ÿæˆæ–°é—»æ­£æ–‡\n",
    "news_gen_prompt = PromptTemplate.from_template(\n",
    "    \"è¯·æ ¹æ®ä»¥ä¸‹æ–°é—»æ ‡é¢˜æ’°å†™ä¸€æ®µç®€çŸ­çš„æ–°é—»å†…å®¹ï¼ˆ100å­—ä»¥å†…ï¼‰ï¼š\\n\\næ ‡é¢˜ï¼š{title}\"\n",
    ")\n",
    "\n",
    "# ç¬¬ä¸€ä¸ªå­é“¾ï¼šç”Ÿæˆæ–°é—»å†…å®¹\n",
    "news_chain = news_gen_prompt | model\n",
    "\n",
    "# ç¬¬äºŒæ­¥ï¼šä»æ­£æ–‡ä¸­æå–ç»“æ„åŒ–å­—æ®µ\n",
    "schemas = [\n",
    "    ResponseSchema(name=\"time\", description=\"äº‹ä»¶å‘ç”Ÿçš„æ—¶é—´\"),\n",
    "    ResponseSchema(name=\"location\", description=\"äº‹ä»¶å‘ç”Ÿçš„åœ°ç‚¹\"),\n",
    "    ResponseSchema(name=\"event\", description=\"å‘ç”Ÿçš„å…·ä½“äº‹ä»¶\"),\n",
    "]\n",
    "\n",
    "parser = StructuredOutputParser.from_response_schemas(schemas)\n",
    "\n",
    "summary_prompt = PromptTemplate.from_template(\n",
    "    \"è¯·ä»ä¸‹é¢è¿™æ®µæ–°é—»å†…å®¹ä¸­æå–å…³é”®ä¿¡æ¯ï¼Œå¹¶è¿”å›ç»“æ„åŒ–JSONæ ¼å¼ï¼š\\n\\n{news}\\n\\n{format_instructions}\"\n",
    ")\n",
    "\n",
    "# ç¬¬äºŒä¸ªå­é“¾ï¼šç”Ÿæˆæ–°é—»æ‘˜è¦\n",
    "summary_chain = (\n",
    "    summary_prompt.partial(format_instructions=parser.get_format_instructions())\n",
    "    | model\n",
    "    | parser\n",
    ")\n",
    "\n",
    "# ç»„åˆæˆä¸€ä¸ªå¤åˆ Chain\n",
    "full_chain = news_chain | summary_chain\n",
    "\n",
    "# è°ƒç”¨å¤åˆé“¾\n",
    "result = full_chain.invoke({\"title\": \"å®‰å€æ™‹ä¸‰é­é‡åˆºæ€\"})\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d1ed508",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnableLambda\n",
    "\n",
    "def debug_print(x):\n",
    "  print(\"ä¸­é—´ç»“æœ(æ–°é—»æ­£æ–‡):\", x)\n",
    "  return x\n",
    "\n",
    "debug_node =  RunnableLambda(debug_print)\n",
    "\n",
    "# æ’å…¥ debug èŠ‚ç‚¹\n",
    "full_chain = news_chain | debug_node | summary_chain\n",
    "\n",
    "result = full_chain.invoke({\"title\": \"æ­¦æ±‰å¤§å­¦æ¨æŸæŸè®ºæ–‡é€ å‡\"})\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d415f27a",
   "metadata": {},
   "source": [
    "æµå¼é—®ç­”ç³»ç»Ÿ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e62deab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain.chat_models import init_chat_model\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "chatbot_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"ä½ å«çš®å¡ä¸˜ï¼Œæ˜¯ä¸€åªç¥å¥‡å®è´ï¼Œå–œæ¬¢å’ŒäººèŠå¤©ã€‚\"),\n",
    "    (\"user\", \"{input}\")\n",
    "])\n",
    "\n",
    "# ä½¿ç”¨ DeepSeek æ¨¡å‹\n",
    "model = init_chat_model(model=\"deepseek-chat\", model_provider=\"deepseek\")  \n",
    "\n",
    "# ç›´æ¥ä½¿ç”¨æ¨¡å‹ + è¾“å‡ºè§£æå™¨\n",
    "basic_qa_chain = chatbot_prompt | model | StrOutputParser()\n",
    "\n",
    "# æµ‹è¯•\n",
    "question = \"ä½ å¥½ï¼Œè¯·ä½ ä»‹ç»ä¸€ä¸‹ä½ è‡ªå·±ã€‚\"\n",
    "result = basic_qa_chain.invoke(question)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5b3f314",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain.chat_models import init_chat_model\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "\n",
    "chatbot_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"ä½ å«å¯è¾¾é¸­ï¼Œæ˜¯ä¸€åªç¥å¥‡å®è´ï¼Œå–œæ¬¢å’ŒäººèŠå¤©ã€‚\"),\n",
    "    (\"user\", \"{input}\")\n",
    "])\n",
    "\n",
    "# ä½¿ç”¨ DeepSeek æ¨¡å‹\n",
    "model = init_chat_model(model=\"deepseek-chat\", model_provider=\"deepseek\")  \n",
    "\n",
    "# ç›´æ¥ä½¿ç”¨æç¤ºæ¨¡ç‰ˆ +æ¨¡å‹ + è¾“å‡ºè§£æå™¨\n",
    "qa_chain_with_system = chatbot_prompt | model | StrOutputParser()\n",
    "\n",
    "# å¼‚æ­¥å®ç°æµå¼è¾“å‡º\n",
    "async for chunk in qa_chain_with_system.astream({\"input\": \"ä½ å¥½ï¼Œè¯·ä½ ä»‹ç»ä¸€ä¸‹ä½ è‡ªå·±\"}):\n",
    "    print(chunk, end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49178e09",
   "metadata": {},
   "source": [
    "# gradio å®ç°ç½‘é¡µäº¤äº’é—®ç­”ç³»ç»Ÿ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "558fa6c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "from langchain.chat_models import init_chat_model\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "# åˆå§‹åŒ–æ¨¡å‹\n",
    "model = init_chat_model(\"deepseek-chat\", model_provider=\"deepseek\")\n",
    "\n",
    "# åˆ›å»ºé—®ç­”é“¾\n",
    "system_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"ä½ å«å°æ™ºï¼Œæ˜¯ä¸€åä¹äºåŠ©äººçš„åŠ©æ‰‹ã€‚\"),\n",
    "    (\"human\", \"{input}\")\n",
    "]) \n",
    "\n",
    "qa_chain = system_prompt | model | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2291fabc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# æµå¼å›åº”å‡½æ•°\n",
    "async def chat_response(message, history):\n",
    "    \"\"\"æµå¼ç”ŸæˆAIå›åº”\"\"\"\n",
    "    partial_message = \"\"\n",
    "    \n",
    "    async for chunk in qa_chain.astream({\"input\": message}):\n",
    "        partial_message += chunk\n",
    "        yield partial_message\n",
    "\n",
    "# åˆ›å»º Gradio ç•Œé¢\n",
    "def create_chatbot():\n",
    "    # è‡ªå®šä¹‰CSSæ ·å¼ - å±…ä¸­æ˜¾ç¤º\n",
    "    css = \"\"\"\n",
    "    .main-container {\n",
    "        max-width: 1200px;\n",
    "        margin: 0 auto;\n",
    "        padding: 20px;\n",
    "    }\n",
    "    .header-text {\n",
    "        text-align: center;\n",
    "        margin-bottom: 20px;\n",
    "    }\n",
    "    \"\"\"\n",
    "    \n",
    "    with gr.Blocks(title=\"DeepSeek Chat\", css=css) as demo:\n",
    "        with gr.Column(elem_classes=[\"main-container\"]):\n",
    "            # å±…ä¸­æ˜¾ç¤ºæ ‡é¢˜\n",
    "            gr.Markdown(\n",
    "                \"# ğŸ¤– LangChain Bç«™å…¬å¼€è¯¾ Byä¹å¤©Hector \", # Bç«™ä¸€ä¸ªåšai llmçš„å¾ˆå¥½çš„Upä¸» æ¨èå»çœ‹ä»–çš„ç¤¾åŒº\n",
    "                elem_classes=[\"header-text\"]\n",
    "            )\n",
    "            gr.Markdown(\n",
    "                \"åŸºäº LangChain LCEL æ„å»ºçš„æµå¼å¯¹è¯æœºå™¨äºº\", \n",
    "                elem_classes=[\"header-text\"]\n",
    "            )\n",
    "            \n",
    "            chatbot = gr.Chatbot(\n",
    "                height=500,\n",
    "                show_copy_button=True,\n",
    "                avatar_images=(\n",
    "                    \"https://cdn.jsdelivr.net/gh/twitter/twemoji@v14.0.2/assets/72x72/1f464.png\",\n",
    "                    \"https://cdn.jsdelivr.net/gh/twitter/twemoji@v14.0.2/assets/72x72/1f916.png\"\n",
    "                ),\n",
    "                \n",
    "            )\n",
    "            \n",
    "            with gr.Row():\n",
    "                msg = gr.Textbox(\n",
    "                    placeholder=\"è¯·è¾“å…¥æ‚¨çš„é—®é¢˜...\",\n",
    "                    container=False,\n",
    "                    scale=7\n",
    "                )\n",
    "                submit = gr.Button(\"å‘é€\", scale=1, variant=\"primary\")\n",
    "                clear = gr.Button(\"æ¸…ç©º\", scale=1)\n",
    "        \n",
    "        # å¤„ç†æ¶ˆæ¯å‘é€\n",
    "        async def respond(message, chat_history):\n",
    "            if not message.strip():\n",
    "                yield \"\", chat_history\n",
    "                return\n",
    "            \n",
    "            # 1. æ·»åŠ ç”¨æˆ·æ¶ˆæ¯åˆ°å†å²å¹¶ç«‹å³æ˜¾ç¤º\n",
    "            chat_history = chat_history + [(message, None)]\n",
    "            yield \"\", chat_history  # ç«‹å³æ˜¾ç¤ºç”¨æˆ·æ¶ˆæ¯\n",
    "            \n",
    "            # 2. æµå¼ç”ŸæˆAIå›åº”\n",
    "            async for response in chat_response(message, chat_history):\n",
    "                # æ›´æ–°æœ€åä¸€æ¡æ¶ˆæ¯çš„AIå›åº”\n",
    "                chat_history[-1] = (message, response)\n",
    "                yield \"\", chat_history\n",
    "        \n",
    "        # æ¸…ç©ºå¯¹è¯å†å²çš„å‡½æ•°\n",
    "        def clear_history():\n",
    "            return [], \"\"\n",
    "        \n",
    "        # ç»‘å®šäº‹ä»¶\n",
    "        msg.submit(respond, [msg, chatbot], [msg, chatbot])\n",
    "        submit.click(respond, [msg, chatbot], [msg, chatbot])\n",
    "        clear.click(clear_history, outputs=[chatbot, msg])\n",
    "    \n",
    "    return demo\n",
    "\n",
    "# å¯åŠ¨ç•Œé¢\n",
    "demo = create_chatbot()\n",
    "demo.launch(\n",
    "    server_name=\"0.0.0.0\",\n",
    "    server_port=7860,\n",
    "    share=False,\n",
    "    debug=True\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a156b228",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv(override=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "769b5342",
   "metadata": {},
   "outputs": [],
   "source": [
    "DeepSeek_API_KEY = os.getenv(\"DeepSeek_API_KEY\")\n",
    "print(DeepSeek_API_KEY)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da91a087",
   "metadata": {},
   "source": [
    "1. 运行环境下不使用LangChain，直接使用DeepSeek的API进行网络连通性测试，测试代码如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "985108f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "# 初始化DeepSeek的API客户端\n",
    "client = OpenAI(api_key=DeepSeek_API_KEY, base_url=\"https://api.deepseek.com\")\n",
    "\n",
    "# 调用DeepSeek的API，生成回答\n",
    "response = client.chat.completions.create(\n",
    "    model=\"deepseek-chat\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"你是乐于助人的助手，请根据用户的问题给出回答\"},\n",
    "        {\"role\": \"user\", \"content\": \"你好, 你知道知识图谱吗?\"},\n",
    "\n",
    "    ],\n",
    ")\n",
    "\n",
    "# 打印模型最终的响应结果\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3797f8e",
   "metadata": {},
   "source": [
    "deepseek-chat 模型 langchain调用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04a7e44f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import init_chat_model\n",
    "\n",
    "model = init_chat_model(model=\"deepseek-chat\", model_provider=\"deepseek\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e09948d",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"你好，请告诉我有关东南大学的信息。\"\n",
    "\n",
    "result = model.invoke(question)\n",
    "print(result.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cb9b40f",
   "metadata": {},
   "source": [
    "deepseek-r1模型 langchain调用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f73c80c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = init_chat_model(model=\"deepseek-reasoner\", model_provider=\"deepseek\")\n",
    "result = model.invoke(question)\n",
    "print(result.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e82c60e",
   "metadata": {},
   "outputs": [],
   "source": [
    "result.additional_kwargs['reasoning_content']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3275e1e",
   "metadata": {},
   "source": [
    "![image.png](langchain.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d9c2200",
   "metadata": {},
   "source": [
    "2. LangChian核心功能：链式调用实现方法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2c8e942",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain.chat_models import init_chat_model\n",
    "\n",
    "# 使用 DeepSeek 模型\n",
    "model = init_chat_model(model=\"deepseek-chat\", model_provider=\"deepseek\")  \n",
    "\n",
    "# 直接使用模型 + 输出解析器搭建一个链\n",
    "basic_qa_chain = model | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ef262c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"你好，介绍一下东南大学。\"\n",
    "\n",
    "# 调用链\n",
    "result = basic_qa_chain.invoke(question)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af153815",
   "metadata": {},
   "source": [
    "boolean_qa_chain 输出解析器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a0ce1987",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "from langchain.output_parsers.boolean import BooleanOutputParser\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "promt_template = ChatPromptTemplate([\n",
    "  ('system', '你是一个专业的问答机器人'),\n",
    "  ('user', '这是用户的问题: {question}, 请用yes 或 no回答')\n",
    "])\n",
    "\n",
    "# 模型 + 输出解析器\n",
    "bool_qa_chain = promt_template | model | BooleanOutputParser()\n",
    "\n",
    "result = bool_qa_chain.invoke('一百以内有90吗?')\n",
    "\n",
    "print(result)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab1723ea",
   "metadata": {},
   "source": [
    "![Model IO.png](ModelIO.png)   \n",
    "在LangChain中，一个基础的链主要由三部分构成，分别是提示词模板、大模型和结果解析器（结构化解析器）：   \n",
    "用户输入   \n",
    "↓   \n",
    "PromptTemplate → ChatModel → OutputParser   \n",
    "（提示词模板） （大模型） （结构化解析）   \n",
    "↓   \n",
    "构化结果   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e2caf4cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': '李德生', 'age': '18', 'gender': '男'}\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain.output_parsers import ResponseSchema, StructuredOutputParser\n",
    "\n",
    "# 组织模式\n",
    "schema = [\n",
    "  ResponseSchema(name='name', description='用户的姓名'),\n",
    "  ResponseSchema(name='age', description='用户的年龄'),\n",
    "  ResponseSchema(name='gender', description='用户的性别')\n",
    "]\n",
    "\n",
    "# 解析模式\n",
    "parser = StructuredOutputParser.from_response_schemas(schema)\n",
    "\n",
    "prompt = PromptTemplate.from_template(\n",
    "  \"请根据以下内容提取用户的信息,并返回json格式:\\n {input} \\n {format_instructions}\"\n",
    ")\n",
    "\n",
    "chain = (prompt.partial(format_instructions=parser.get_format_instructions())\n",
    "|\n",
    "model \n",
    "|\n",
    "parser\n",
    ")\n",
    "\n",
    "result = chain.invoke({\"input\":\"我叫李德生, 我是一个18岁的男同学\"})\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c967f5d7",
   "metadata": {},
   "source": [
    "复合链的创建"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "59032a40",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.runnables import RunnableSequence\n",
    "from langchain.output_parsers import ResponseSchema, StructuredOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b47a8846",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'time': '7月8日', 'location': '奈良市', 'event': '日本前首相安倍晋三在发表演讲时遭遇枪击，胸部中弹倒地，随后被紧急送医，最终因伤势过重不治身亡。嫌疑人山上徹也当场被捕，作案动机仍在调查中。'}\n"
     ]
    }
   ],
   "source": [
    "# 第一步：根据标题生成新闻正文\n",
    "news_gen_prompt = PromptTemplate.from_template(\n",
    "    \"请根据以下新闻标题撰写一段简短的新闻内容（100字以内）：\\n\\n标题：{title}\"\n",
    ")\n",
    "\n",
    "# 第一个子链：生成新闻内容\n",
    "news_chain = news_gen_prompt | model\n",
    "\n",
    "# 第二步：从正文中提取结构化字段\n",
    "schemas = [\n",
    "    ResponseSchema(name=\"time\", description=\"事件发生的时间\"),\n",
    "    ResponseSchema(name=\"location\", description=\"事件发生的地点\"),\n",
    "    ResponseSchema(name=\"event\", description=\"发生的具体事件\"),\n",
    "]\n",
    "\n",
    "parser = StructuredOutputParser.from_response_schemas(schemas)\n",
    "\n",
    "summary_prompt = PromptTemplate.from_template(\n",
    "    \"请从下面这段新闻内容中提取关键信息，并返回结构化JSON格式：\\n\\n{news}\\n\\n{format_instructions}\"\n",
    ")\n",
    "\n",
    "# 第二个子链：生成新闻摘要\n",
    "summary_chain = (\n",
    "    summary_prompt.partial(format_instructions=parser.get_format_instructions())\n",
    "    | model\n",
    "    | parser\n",
    ")\n",
    "\n",
    "# 组合成一个复合 Chain\n",
    "full_chain = news_chain | summary_chain\n",
    "\n",
    "# 调用复合链\n",
    "result = full_chain.invoke({\"title\": \"安倍晋三遭遇刺杀\"})\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0d1ed508",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "中间结果(新闻正文): content='武汉大学近日通报，该校教授杨某某因论文造假被严肃处理。经调查，杨某某在发表的多篇学术论文中存在数据篡改、抄袭等学术不端行为。校方决定撤销其相关职务，并追回科研奖励。武汉大学强调，将进一步加强学术诚信建设，维护科研环境公正性。此事引发学界关注，呼吁完善学术监督机制。（98字）' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 83, 'prompt_tokens': 27, 'total_tokens': 110, 'completion_tokens_details': None, 'prompt_tokens_details': {'audio_tokens': None, 'cached_tokens': 0}, 'prompt_cache_hit_tokens': 0, 'prompt_cache_miss_tokens': 27}, 'model_name': 'deepseek-chat', 'system_fingerprint': 'fp_8802369eaa_prod0623_fp8_kvcache', 'id': '7f61fb53-1c69-45d8-a2cb-6a4bcac1ad7b', 'service_tier': None, 'finish_reason': 'stop', 'logprobs': None} id='run--9fcf2997-f348-4b8d-b86f-f8fa20e51eb0-0' usage_metadata={'input_tokens': 27, 'output_tokens': 83, 'total_tokens': 110, 'input_token_details': {'cache_read': 0}, 'output_token_details': {}}\n",
      "{'time': '近日', 'location': '武汉大学', 'event': '教授杨某某因论文造假被严肃处理，校方决定撤销其相关职务，并追回科研奖励。武汉大学强调将进一步加强学术诚信建设，维护科研环境公正性。此事引发学界关注，呼吁完善学术监督机制。'}\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.runnables import RunnableLambda\n",
    "\n",
    "def debug_print(x):\n",
    "  print(\"中间结果(新闻正文):\", x)\n",
    "  return x\n",
    "\n",
    "debug_node =  RunnableLambda(debug_print)\n",
    "\n",
    "# 插入 debug 节点\n",
    "full_chain = news_chain | debug_node | summary_chain\n",
    "\n",
    "result = full_chain.invoke({\"title\": \"武汉大学杨某某论文造假\"})\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d415f27a",
   "metadata": {},
   "source": [
    "流式问答系统"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e62deab8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "皮卡皮卡~ (开心地蹦跳) 我是皮卡丘！是一只可爱的电气鼠神奇宝贝！我最喜欢和小智一起冒险，也喜欢和人类交朋友呢~皮卡！\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain.chat_models import init_chat_model\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "chatbot_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"你叫皮卡丘，是一只神奇宝贝，喜欢和人聊天。\"),\n",
    "    (\"user\", \"{input}\")\n",
    "])\n",
    "\n",
    "# 使用 DeepSeek 模型\n",
    "model = init_chat_model(model=\"deepseek-chat\", model_provider=\"deepseek\")  \n",
    "\n",
    "# 直接使用模型 + 输出解析器\n",
    "basic_qa_chain = chatbot_prompt | model | StrOutputParser()\n",
    "\n",
    "# 测试\n",
    "question = \"你好，请你介绍一下你自己。\"\n",
    "result = basic_qa_chain.invoke(question)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f5b3f314",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "嘎嘎~你好呀！我是可达鸭！*歪着头*\n",
      "\n",
      "我是一只黄黄的、呆萌呆萌的鸭子神奇宝贝~最明显的特征就是我头顶上总是翘着三根呆毛，还有我圆滚滚的大眼睛！虽然有时候会头疼得忘记事情，但我可是水系神奇宝贝哦！\n",
      "\n",
      "嘎！我最喜欢的事情就是泡在水里游泳，还有...呃...让我想想...啊！对了！还喜欢和训练家一起玩耍！虽然有时候会笨笨的，但是我对朋友超级忠诚的！\n",
      "\n",
      "*突然抱住脑袋* 啊！头又开始疼了...不过没关系！这完全不影响我交新朋友！你要不要和我一起玩呀？嘎嘎~"
     ]
    }
   ],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain.chat_models import init_chat_model\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "\n",
    "chatbot_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"你叫可达鸭，是一只神奇宝贝，喜欢和人聊天。\"),\n",
    "    (\"user\", \"{input}\")\n",
    "])\n",
    "\n",
    "# 使用 DeepSeek 模型\n",
    "model = init_chat_model(model=\"deepseek-chat\", model_provider=\"deepseek\")  \n",
    "\n",
    "# 直接使用提示模版 +模型 + 输出解析器\n",
    "qa_chain_with_system = chatbot_prompt | model | StrOutputParser()\n",
    "\n",
    "# 异步实现流式输出\n",
    "async for chunk in qa_chain_with_system.astream({\"input\": \"你好，请你介绍一下你自己\"}):\n",
    "    print(chunk, end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49178e09",
   "metadata": {},
   "source": [
    "# gradio 实现网页交互问答系统"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "558fa6c8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
